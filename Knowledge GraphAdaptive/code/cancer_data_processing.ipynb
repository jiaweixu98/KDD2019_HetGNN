{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cancer data的数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pickle as pk\n",
    "# 保证文献有作者和V\n",
    "A_max = 753072\n",
    "P_max = 412500\n",
    "V_max = 545982"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"../data/academic/paper_author.csv\", \"r\")\n",
    "paper_author ={}\n",
    "author_paper ={}\n",
    "for line in f:\n",
    "    line = line.strip().split(',')\n",
    "    if line[0] == 'PMID':\n",
    "        continue\n",
    "    elif line[0] in paper_author:\n",
    "        paper_author[line[0]].append(line[3])\n",
    "    else:\n",
    "        paper_author[line[0]] = [line[3]]\n",
    "    if line[3] in author_paper:\n",
    "        author_paper[line[3]].append(line[0])\n",
    "    else:\n",
    "        author_paper[line[3]] = [line[0]]\n",
    "f.close()\n",
    "# 0[pmid],3[aid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"../data/academic/paper_bioentity.csv\", \"r\")\n",
    "paper_bioentity = {}\n",
    "bioentity_paper = {}\n",
    "for line in f:\n",
    "    line = line.strip().split(',')\n",
    "    if line[0] == 'PMID':\n",
    "        continue\n",
    "    elif line[0] in paper_bioentity:\n",
    "        paper_bioentity[line[0]].append(line[1])\n",
    "    else:\n",
    "        paper_bioentity[line[0]] = [line[1]]\n",
    "    if line[1] in bioentity_paper:\n",
    "        bioentity_paper[line[1]].append(line[0])\n",
    "    else:\n",
    "        bioentity_paper[line[1]] = [line[0]]\n",
    "f.close()\n",
    "# 0[pmid],1[mention]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "412500"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 只保留既有author关系，也有entity关系的文献\n",
    "PID_set = paper_author.keys() & paper_bioentity.keys()\n",
    "len(PID_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1761904it [00:10, 172895.61it/s]\n"
     ]
    }
   ],
   "source": [
    "# 重复上边的代码，重新弄一下；限定到PID\n",
    "f = open(\"../data/academic/paper_author.csv\", \"r\")\n",
    "paper_author ={}\n",
    "author_paper ={}\n",
    "for line in tqdm(f):\n",
    "    line = line.strip().split(',')\n",
    "    if line[0] not in PID_set:\n",
    "        continue\n",
    "    if line[0] in paper_author:\n",
    "        paper_author[line[0]].append(line[3])\n",
    "    else:\n",
    "        paper_author[line[0]] = [line[3]]\n",
    "    if line[3] in author_paper:\n",
    "        author_paper[line[3]].append(line[0])\n",
    "    else:\n",
    "        author_paper[line[3]] = [line[0]]\n",
    "f.close()\n",
    "# 0[pmid],3[aid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"../data/academic/paper_bioentity.csv\", \"r\")\n",
    "paper_bioentity = {}\n",
    "bioentity_paper = {}\n",
    "for line in f:\n",
    "    line = line.strip().split(',')\n",
    "    if line[0] not in PID_set:\n",
    "        continue\n",
    "    if line[0] in paper_bioentity:\n",
    "        paper_bioentity[line[0]].append(line[1])\n",
    "    else:\n",
    "        paper_bioentity[line[0]] = [line[1]]\n",
    "    if line[1] in bioentity_paper:\n",
    "        bioentity_paper[line[1]].append(line[0])\n",
    "    else:\n",
    "        bioentity_paper[line[1]] = [line[0]]\n",
    "f.close()\n",
    "# 0[pmid],1[mention]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "412500"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paper_author.keys() & paper_bioentity.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(753072, 545982)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(author_paper),len(bioentity_paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将id变为顺序数字index（Pcount）\n",
    "PID_trans_Pcount = {}\n",
    "Pcount_trans_PID = {}\n",
    "\n",
    "#paper从0开始\n",
    "count = 0\n",
    "for PID in PID_set:\n",
    "    PID_trans_Pcount[PID] = count\n",
    "    Pcount_trans_PID[count] = PID\n",
    "    count += 1\n",
    "pk.dump(PID_trans_Pcount,open('PID_trans_Pcount.pkl','wb'))\n",
    "pk.dump(Pcount_trans_PID,open('Pcount_trans_PID.pkl','wb'))\n",
    "# author 从0开始\n",
    "\n",
    "\n",
    "count = 0\n",
    "AID_trans_Acount = {}\n",
    "Acount_trans_AID = {}\n",
    "\n",
    "for AID in author_paper.keys():\n",
    "    AID_trans_Acount[AID] = count\n",
    "    Acount_trans_AID[count] = AID\n",
    "    count += 1\n",
    "pk.dump(AID_trans_Acount,open('AID_trans_Acount.pkl','wb'))\n",
    "pk.dump(Acount_trans_AID,open('Acount_trans_AID.pkl','wb'))\n",
    "# bioentity 从0开始\n",
    "count = 0\n",
    "BID_trans_Bcount = {}\n",
    "Bcount_trans_BID = {}\n",
    "for BID in bioentity_paper.keys():\n",
    "    BID_trans_Bcount[BID] = count\n",
    "    Bcount_trans_BID[count] = BID\n",
    "    count += 1\n",
    "pk.dump(BID_trans_Bcount,open('BID_trans_Bcount.pkl','wb'))\n",
    "pk.dump(Bcount_trans_BID,open('Bcount_trans_BID.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pcount_trans_PID = pk.load(open('Pcount_trans_PID.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_c2author_c = {}\n",
    "author_c2paper_c = {}\n",
    "paper_c2bio_c = {}\n",
    "bio_c2paper_c = {}\n",
    "for k,v in paper_author.items():\n",
    "    # k,PId; V AID；下面转化为数字符号；实际上只转换bioentity应该就可以，在此全部转换，以防万一\n",
    "    paper_c2author_c[PID_trans_Pcount[k]] = list(map(lambda x: AID_trans_Acount[x],v))\n",
    "# 以下基本相同\n",
    "for k,v in author_paper.items():\n",
    "    author_c2paper_c[AID_trans_Acount[k]] = list(map(lambda x: PID_trans_Pcount[x],v))\n",
    "\n",
    "for k,v in paper_bioentity.items():\n",
    "    paper_c2bio_c[PID_trans_Pcount[k]] = list(map(lambda x: BID_trans_Bcount[x],v))\n",
    "\n",
    "for k,v in bioentity_paper.items():\n",
    "    bio_c2paper_c[BID_trans_Bcount[k]] = list(map(lambda x: PID_trans_Pcount[x],v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p_a_list_train = [[] for k in range(P_max)]\n",
    "# a_p_list_train = [[] for k in range(A_max)]\n",
    "# v_p_list_train = [[] for k in range(V_max)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_a_list_train_f = open(\"../data/academic/p_a_list_train.txt\", \"w\")\n",
    "import operator\n",
    "sorted_paper_c2author_c = sorted(paper_c2author_c.items(),key=operator.itemgetter(0))\n",
    "for k, v in  dict(sorted_paper_c2author_c).items():\n",
    "    p_a_list_train_f.write(str(k) + \":\")\n",
    "    for tt in range(len(v)-1):\n",
    "        p_a_list_train_f.write(str(v[tt]) + \",\")\n",
    "    p_a_list_train_f.write(str(v[-1]))\n",
    "    p_a_list_train_f.write(\"\\n\")\n",
    "p_a_list_train_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_p_list_train_f = open(\"../data/academic/a_p_list_train.txt\", \"w\")\n",
    "sorted_author_c2paper_c = sorted(author_c2paper_c.items(),key=operator.itemgetter(0))\n",
    "for k, v in  dict(sorted_author_c2paper_c).items():\n",
    "    a_p_list_train_f.write(str(k) + \":\")\n",
    "    for tt in range(len(v)-1):\n",
    "        a_p_list_train_f.write(str(v[tt]) + \",\")\n",
    "    a_p_list_train_f.write(str(v[-1]))\n",
    "    a_p_list_train_f.write(\"\\n\")\n",
    "a_p_list_train_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_p_list_train_f = open(\"../data/academic/v_p_list_train.txt\", \"w\")\n",
    "sorted_bio_c2paper_c = sorted(bio_c2paper_c.items(),key=operator.itemgetter(0))\n",
    "for k, v in  dict(sorted_bio_c2paper_c).items():\n",
    "    v_p_list_train_f.write(str(k) + \":\")\n",
    "    for tt in range(len(v)-1):\n",
    "        v_p_list_train_f.write(str(v[tt]) + \",\")\n",
    "    v_p_list_train_f.write(str(v[-1]))\n",
    "    v_p_list_train_f.write(\"\\n\")\n",
    "v_p_list_train_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_v_f = open(\"../data/academic/p_v.txt\", \"w\")\n",
    "sorted_paper_c2bio_c = sorted(paper_c2bio_c.items(),key=operator.itemgetter(0))\n",
    "for k, v in  dict(sorted_paper_c2bio_c).items():\n",
    "    p_v_f.write(str(k) + \":\")\n",
    "    for tt in range(len(v)-1):\n",
    "        p_v_f.write(str(v[tt]) + \",\")\n",
    "    p_v_f.write(str(v[-1]))\n",
    "    p_v_f.write(\"\\n\")\n",
    "p_v_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = open(\"../data/academic/node_net_embedding.txt\", \"r\")\n",
    "\n",
    "\n",
    "# v_dict = {}\n",
    "# for line in f:\n",
    "#     line = line.strip().split(' ')\n",
    "#     if len(line) != 129 or line[0][0] !='v':\n",
    "#         continue\n",
    "#     v_dict[int(line[0][1:])] = line[1:]\n",
    "# f.close()\n",
    "# f = open(\"../data/academic/node_net_embedding.txt\", \"r\")\n",
    "\n",
    "# a_dict = {}\n",
    "# for line in f:\n",
    "#     line = line.strip().split(' ')\n",
    "#     if len(line) != 129 or line[0][0] !='a':\n",
    "#         continue\n",
    "#     a_dict[int(line[0][1:])] = line[1:]\n",
    "# f.close()\n",
    "# f = open(\"../data/academic/node_net_embedding.txt\", \"r\")\n",
    "\n",
    "# # 0[pmid],3[aid]\n",
    "# p_dict = {}\n",
    "# for line in f:\n",
    "#     line = line.strip().split(' ')\n",
    "#     if len(line) != 129 or line[0][0] !='p':\n",
    "#         continue\n",
    "#     p_dict[int(line[0][1:])] = line[1:]\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = open(\"../data/academic/deepwalk_author_embeddings.txt\", \"w\")\n",
    "# for k,v in a_dict.items():\n",
    "#     f.write('a'+str(k))\n",
    "#     for i in v:\n",
    "#         f.write(' '+i)\n",
    "#     f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print('hello world')\n",
    "Pcount_trans_PID = pk.load(open('Pcount_trans_PID.pkl','rb'))\n",
    "# PID_trans_Pcount = pk.load(open('PID_trans_Pcount.pkl','rb'))\n",
    "# AID_trans_Acount = pk.load(open('AID_trans_Acount.pkl','rb'))\n",
    "Acount_trans_AID = pk.load(open('Acount_trans_AID.pkl','rb'))\n",
    "# BID_trans_Bcount = pk.load(open('BID_trans_Bcount.pkl','rb'))\n",
    "Bcount_trans_BID = pk.load(open('Bcount_trans_BID.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1711551it [00:37, 45108.58it/s]\n"
     ]
    }
   ],
   "source": [
    "f = open(\"../data/academic/0_node_embedding.txt\", \"r\")\n",
    "fa = open(\"../data/academic/author_processed_0_node_embedding.txt\", \"w\")\n",
    "fp = open(\"../data/academic/paper_processed_0_node_embedding.txt\", \"w\")\n",
    "fb = open(\"../data/academic/entity_processed_0_node_embedding.txt\", \"w\")\n",
    "for line in tqdm(f):\n",
    "    line = line.strip().split(' ')\n",
    "    if line[0][0] == 'a':\n",
    "        fa.write(Acount_trans_AID[int(line[0][1:])])\n",
    "        for i in line[1:]:\n",
    "            fa.write(' '+i)\n",
    "        fa.write('\\n')\n",
    "        continue\n",
    "    if line[0][0] == 'v':\n",
    "        fb.write(Bcount_trans_BID[int(line[0][1:])])\n",
    "        for i in line[1:]:\n",
    "            fb.write(' '+i)\n",
    "        fb.write('\\n')\n",
    "        continue\n",
    "    if line[0][0] == 'p':\n",
    "        fp.write(Pcount_trans_PID[int(line[0][1:])])\n",
    "        for i in line[1:]:\n",
    "            fp.write(' '+i)\n",
    "        fp.write('\\n')\n",
    "f.close()\n",
    "fa.close()\n",
    "fp.close()\n",
    "fb.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38j",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "87ed1b9757df4d9aa61e080f4bb12e710ce5f940767ccc51a9b9d9ffaba78d60"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
